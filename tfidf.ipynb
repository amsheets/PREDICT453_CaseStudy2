{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob as tb\n",
    "import math\n",
    "import io\n",
    "import codecs\n",
    "from __future__ import division\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      administration\n",
      "0                     americanEnergy\n",
      "1                               bank\n",
      "2                        barackObama\n",
      "3                             border\n",
      "4                             bridge\n",
      "5                           business\n",
      "6                           campaign\n",
      "7                      climateChange\n",
      "8                           congress\n",
      "9                       conservative\n",
      "10                         democracy\n",
      "11                          democrat\n",
      "12                   democraticParty\n",
      "13                           economy\n",
      "14                          election\n",
      "15                            energy\n",
      "16                       environment\n",
      "17                        government\n",
      "18                              hack\n",
      "19                    hillaryClinton\n",
      "20                   houseRepublican\n",
      "21                         immigrant\n",
      "22                       immigration\n",
      "23                intelligenceAgency\n",
      "24                  keystonePipeline\n",
      "25                          lawmaker\n",
      "26                            leader\n",
      "27                       legislation\n",
      "28                             media\n",
      "29                            mexico\n",
      "..                               ...\n",
      "100                              fbi\n",
      "101     kremlin election involvement\n",
      "102                 mickhail kulagin\n",
      "103                       bankruptcy\n",
      "104                             bill\n",
      "105                       Healthcare\n",
      "106                           reform\n",
      "107                  foreign country\n",
      "108               lawful restriction\n",
      "109                    public safety\n",
      "110                          travelï¿½\n",
      "111                    United States\n",
      "112         American Health Care Act\n",
      "113                      deductibles\n",
      "114                         premiums\n",
      "115               repeal and replace\n",
      "116                             Ryan\n",
      "117                     construction\n",
      "118                             cost\n",
      "119  Department of Homeland Security\n",
      "120               U.S. Mexico border\n",
      "121                        Community\n",
      "122                   Small Business\n",
      "123        Small Business Confidence\n",
      "124              Affordable Care Act\n",
      "125                      Regulations\n",
      "126         Small business Community\n",
      "127            United States Economy\n",
      "128        Small business confidence\n",
      "129                     tax overhaul\n",
      "\n",
      "[130 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "os.chdir('/users/asheets/Documents/Work_Computer_new/Work_Computer/Grad_School/PREDICT_453/Notebooks/DSI/')\n",
    "\n",
    "all_docs = []\n",
    "d = 24\n",
    "\n",
    "cachedStopWords = nltk.corpus.stopwords.words('english')\n",
    "pattern = re.compile(r'\\b(' + r'|'.join(cachedStopWords) + r')\\b\\s*')\n",
    "\n",
    "for i in range(16):\n",
    "    doc_name = 'DSI' + str(d) + '.txt'\n",
    "    try:\n",
    "        with open(doc_name, 'r') as f:\n",
    "            sample = f.read()\n",
    "        sample = sample.decode('utf-8')\n",
    "        sample = sample.lower()\n",
    "        sample = ''.join([i for i in sample if not i.isdigit()])\n",
    "        sample = pattern.sub('', sample)\n",
    "        sample = \"\".join(l for l in sample if l not in string.punctuation)\n",
    "        sample2 = \" \".join(k for k in tb(sample).noun_phrases)\n",
    "        all_docs.append({'DSInum': d, 'raw_text': sample, 'noun_phrases_only':\n",
    "        sample2})\n",
    "        d = d + 1\n",
    "    except IOError:\n",
    "        d = d + 1\n",
    "        pass\n",
    "\n",
    "RTV = pd.read_csv('RTV.txt')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#http://stevenloria.com/finding-important-words-in-a-document-using-tf-idf/\n",
    "\n",
    "#computes \"term frequency\" which is the number of times a word appears in a document blob, \n",
    "#normalized by dividing by the total number of words in blob. \n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "#returns the number of documents containing word. A generator expression is passed to the sum() function.\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "#computes \"inverse document frequency\" which measures how common a word is among all documents in bloblist. \n",
    "#The more common a word is, the lower its idf. \n",
    "#We take the ratio of the total number of documents to the number of documents containing word, \n",
    "#then take the log of that. Add 1 to the divisor to prevent division by zero.\n",
    "def idf(word, bloblist):\n",
    "     return math.log(len(bloblist) / float(n_containing(word, bloblist)))\n",
    "\n",
    "#computes the TF-IDF score. It is simply the product of  tf and idf.\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf_idf_doc1</th>\n",
       "      <th>tf_idf_doc2</th>\n",
       "      <th>tf_idf_doc3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>future</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>energy</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>creation</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>economic</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>companies</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>workers</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  tf_idf_doc1  tf_idf_doc2  tf_idf_doc3\n",
       "1981     future     0.014967          NaN          NaN\n",
       "283      energy     0.011048     0.008275          NaN\n",
       "782    creation     0.005987          NaN          NaN\n",
       "805    economic     0.005987          NaN          NaN\n",
       "809   companies     0.005987          NaN          NaN\n",
       "811     workers     0.005987          NaN          NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare all three articles\n",
    "blob1 = tb(sample1)\n",
    "blob2 = blob1.noun_phrases\n",
    "term_freq = [tf(word,blob1) for word in blob1.words]\n",
    "tf_df1 = pd.DataFrame({'word': blob1.words, 'doc1_term_freq': term_freq})\n",
    "\n",
    "blob2 = tb(sample2)\n",
    "term_freq = [tf(word,blob2) for word in blob2.words]\n",
    "tf_df2 = pd.DataFrame({'word': blob2.words, 'doc2_term_freq': term_freq})\n",
    "\n",
    "blob3 = tb(sample3)\n",
    "term_freq = [tf(word,blob3) for word in blob3.words]\n",
    "tf_df3 = pd.DataFrame({'word': blob3.words, 'doc3_term_freq': term_freq})\n",
    "\n",
    "all_tf = pd.merge(pd.merge(tf_df1,tf_df2,on='word',how='outer'),tf_df3,on='word',how='outer').drop_duplicates()\n",
    "\n",
    "bloblist = [blob1,blob2,blob3]\n",
    "\n",
    "docs_containing1 = pd.DataFrame({'word': blob1.words, 'doc_freq': [n_containing(word,bloblist) for word in blob1.words]})\n",
    "docs_containing2 = pd.DataFrame({'word': blob2.words, 'doc_freq': [n_containing(word,bloblist) for word in blob2.words]})\n",
    "docs_containing3 = pd.DataFrame({'word': blob3.words, 'doc_freq': [n_containing(word,bloblist) for word in blob3.words]})\n",
    "\n",
    "doc_freq = pd.concat([docs_containing1,docs_containing2,docs_containing3]).drop_duplicates().reset_index(drop=True)\n",
    "df = pd.merge(doc_freq,all_tf,on='word',how='inner')\n",
    "df = df.sort_values(\"doc_freq\",ascending=False)\n",
    "\n",
    "df['intermediate_calc'] = (len(bloblist) / df['doc_freq']).astype(float)\n",
    "df['idf'] = df['intermediate_calc'].apply(math.log)\n",
    "df = df.sort_values(\"idf\",ascending=True)\n",
    "\n",
    "\n",
    "scores1 = pd.DataFrame({'word': blob1.words, 'tf_idf_doc1': [tfidf(word, blob1, bloblist) for word in blob1.words]})\n",
    "scores2 = pd.DataFrame({'word': blob2.words, 'tf_idf_doc2': [tfidf(word, blob2, bloblist) for word in blob2.words]})\n",
    "scores3 = pd.DataFrame({'word': blob3.words, 'tf_idf_doc3': [tfidf(word, blob3, bloblist) for word in blob3.words]})\n",
    "\n",
    "all_tfidf= pd.merge(pd.merge(scores1,scores2,on='word',how='outer'),scores3,on='word',how='outer').drop_duplicates()\n",
    "all_tfidf = all_tfidf[['word', 'tf_idf_doc1', 'tf_idf_doc2', 'tf_idf_doc3']]\n",
    "all_tfidf = all_tfidf.sort_values(by=['tf_idf_doc1', 'tf_idf_doc2','tf_idf_doc3'], ascending=[False,False,False])\n",
    "all_tfidf.head(n=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf_idf_doc1</th>\n",
       "      <th>tf_idf_doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>future</td>\n",
       "      <td>0.009443</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>back</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>new</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>white</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>house</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>job</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  tf_idf_doc1  tf_idf_doc2\n",
       "501  future     0.009443          NaN\n",
       "360    back     0.007555          NaN\n",
       "242     new     0.005666          NaN\n",
       "592   white     0.005666          NaN\n",
       "595   house     0.005666          NaN\n",
       "249     job     0.003777          NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Compare just the two articles we know to be similar\n",
    "two_tf = pd.merge(tf_df1,tf_df2,on='word',how='outer').drop_duplicates()\n",
    "\n",
    "bloblist = [blob1,blob2]\n",
    "\n",
    "docs_containing1 = pd.DataFrame({'word': blob1.words, 'doc_freq': [n_containing(word,bloblist) for word in blob1.words]})\n",
    "docs_containing2 = pd.DataFrame({'word': blob2.words, 'doc_freq': [n_containing(word,bloblist) for word in blob2.words]})\n",
    "\n",
    "doc_freq = pd.concat([docs_containing1,docs_containing2]).drop_duplicates().reset_index(drop=True)\n",
    "df = pd.merge(doc_freq,two_tf,on='word',how='inner')\n",
    "df = df.sort_values(\"doc_freq\",ascending=False)\n",
    "\n",
    "df['intermediate_calc'] = (len(bloblist) / df['doc_freq']).astype(float)\n",
    "df['idf'] = df['intermediate_calc'].apply(math.log)\n",
    "df = df.sort_values(\"idf\",ascending=False)\n",
    "\n",
    "scores1 = pd.DataFrame({'word': blob1.words, 'tf_idf_doc1': [tfidf(word, blob1, bloblist) for word in blob1.words]})\n",
    "scores2 = pd.DataFrame({'word': blob2.words, 'tf_idf_doc2': [tfidf(word, blob2, bloblist) for word in blob2.words]})\n",
    "\n",
    "two_tfidf= pd.merge(scores1,scores2,on='word',how='outer').drop_duplicates()\n",
    "two_tfidf = two_tfidf[['word', 'tf_idf_doc1', 'tf_idf_doc2']]\n",
    "two_tfidf = two_tfidf.sort_values(by=['tf_idf_doc1', 'tf_idf_doc2'], ascending=[False,False])\n",
    "two_tfidf.head(n=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: future, TF-IDF: 0.01497\n",
      "\tWord: energy, TF-IDF: 0.01105\n",
      "\tWord: four, TF-IDF: 0.00599\n",
      "\tWord: previous, TF-IDF: 0.00599\n",
      "\tWord: workers, TF-IDF: 0.00599\n",
      "\tWord: environment, TF-IDF: 0.00599\n",
      "\tWord: effects, TF-IDF: 0.00599\n",
      "\tWord: companies, TF-IDF: 0.00599\n",
      "\tWord: gore, TF-IDF: 0.00599\n",
      "\tWord: creation, TF-IDF: 0.00599\n",
      "Top words in document 2\n",
      "\tWord: paris, TF-IDF: 0.01121\n",
      "\tWord: energy, TF-IDF: 0.00827\n",
      "\tWord: industries, TF-IDF: 0.00747\n",
      "\tWord: rose, TF-IDF: 0.00747\n",
      "\tWord: global, TF-IDF: 0.00747\n",
      "\tWord: oil, TF-IDF: 0.00747\n",
      "\tWord: per, TF-IDF: 0.00747\n",
      "\tWord: accord, TF-IDF: 0.00747\n",
      "\tWord: undo, TF-IDF: 0.00747\n",
      "\tWord: activist, TF-IDF: 0.00747\n",
      "Top words in document 3\n",
      "\tWord: fbi, TF-IDF: 0.01836\n",
      "\tWord: us, TF-IDF: 0.01836\n",
      "\tWord: russia, TF-IDF: 0.0153\n",
      "\tWord: intelligence, TF-IDF: 0.01428\n",
      "\tWord: steele, TF-IDF: 0.01122\n",
      "\tWord: russian, TF-IDF: 0.0102\n",
      "\tWord: people, TF-IDF: 0.00918\n",
      "\tWord: investigation, TF-IDF: 0.00816\n",
      "\tWord: dossier, TF-IDF: 0.00714\n",
      "\tWord: cia, TF-IDF: 0.00714\n"
     ]
    }
   ],
   "source": [
    "#compare all three using all pre-defined functions\n",
    "bloblist = [blob1,blob2,blob3]\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: future, TF-IDF: 0.00944\n",
      "\tWord: back, TF-IDF: 0.00755\n",
      "\tWord: new, TF-IDF: 0.00567\n",
      "\tWord: house, TF-IDF: 0.00567\n",
      "\tWord: white, TF-IDF: 0.00567\n",
      "\tWord: four, TF-IDF: 0.00378\n",
      "\tWord: previous, TF-IDF: 0.00378\n",
      "\tWord: workers, TF-IDF: 0.00378\n",
      "\tWord: environment, TF-IDF: 0.00378\n",
      "\tWord: stop, TF-IDF: 0.00378\n",
      "Top words in document 2\n",
      "\tWord: paris, TF-IDF: 0.00707\n",
      "\tWord: industries, TF-IDF: 0.00472\n",
      "\tWord: rose, TF-IDF: 0.00472\n",
      "\tWord: global, TF-IDF: 0.00472\n",
      "\tWord: oil, TF-IDF: 0.00472\n",
      "\tWord: per, TF-IDF: 0.00472\n",
      "\tWord: accord, TF-IDF: 0.00472\n",
      "\tWord: undo, TF-IDF: 0.00472\n",
      "\tWord: activist, TF-IDF: 0.00472\n",
      "\tWord: groups, TF-IDF: 0.00472\n"
     ]
    }
   ],
   "source": [
    "#compare similar docs using all pre-defined functions\n",
    "bloblist = [blob1,blob2]\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
