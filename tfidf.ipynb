{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob as tb\n",
    "import math\n",
    "import io\n",
    "import codecs\n",
    "from __future__ import division\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#http://stevenloria.com/finding-important-words-in-a-document-using-tf-idf/\n",
    "\n",
    "#computes \"term frequency\" which is the number of times a word appears in a document blob, \n",
    "#normalized by dividing by the total number of words in blob. \n",
    "def tf1(word, blob):\n",
    "    return blob.words.count(word)\n",
    "\n",
    "def tf2(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "#returns the number of documents containing word. A generator expression is passed to the sum() function.\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "#computes \"inverse document frequency\" which measures how common a word is among all documents in bloblist. \n",
    "#The more common a word is, the lower its idf. \n",
    "#We take the ratio of the total number of documents to the number of documents containing word, \n",
    "#then take the log of that. Add 1 to the divisor to prevent division by zero.\n",
    "def idf(word, bloblist):\n",
    "     return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "#computes the TF-IDF score. It is simply the product of  tf and idf.\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "os.chdir('/users/asheets/Documents/Work_Computer_new/Work_Computer/Grad_School/PREDICT_453/Notebooks/DSI/')\n",
    "\n",
    "all_docs = []\n",
    "blob_list = []\n",
    "d = 1\n",
    "\n",
    "cachedStopWords = nltk.corpus.stopwords.words('english')\n",
    "pattern = re.compile(r'\\b(' + r'|'.join(cachedStopWords) + r')\\b\\s*')\n",
    "\n",
    "for i in range(40):\n",
    "    doc_name = 'DSI' + str(d) + '.txt'\n",
    "    try:\n",
    "        with open(doc_name, 'r') as f:\n",
    "            sample = f.read()\n",
    "        sample = sample.decode('utf-8')\n",
    "       #sample = sample.decode('ascii')\n",
    "        sample = sample.lower()\n",
    "        sample = re.sub(r'[^\\w]', ' ', sample)\n",
    "        sample = ''.join([i for i in sample if not i.isdigit()])\n",
    "        sample = pattern.sub('', sample)\n",
    "        sample = \"\".join(l for l in sample if l not in string.punctuation)\n",
    "        sample2 = \" \".join(k for k in tb(sample).noun_phrases)\n",
    "        all_docs.append({'DSInum': d, 'raw_text': sample, 'noun_phrases_only':\n",
    "        sample2})\n",
    "        blob_list.append(tb(sample2))\n",
    "        d = d + 1\n",
    "    except IOError:\n",
    "        d = d + 1\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#compare my article\n",
    "blob1 = tb(all_documents['noun_phrases_only'][23])\n",
    "term_freq = [tf1(word,blob1) for word in blob1.words]\n",
    "term_rel_freq = [tf2(word,blob1) for word in blob1.words]\n",
    "tf_df1 = pd.DataFrame({'word': blob1.words, 'doc1_term_freq': term_freq, 'doc1_term_rel_freq': term_rel_freq})\n",
    "\n",
    "docs_containing1 = pd.DataFrame({'word': blob1.words, 'doc_freq': [n_containing(word,blob_list) for word in blob1.words]})\n",
    "\n",
    "df = pd.merge(tf_df1,docs_containing1,on='word',how='outer').drop_duplicates()\n",
    "\n",
    "df['intermediate_calc'] = (len(blob_list) / df['doc_freq']).astype(float)\n",
    "df['idf'] = df['intermediate_calc'].apply(math.log)\n",
    "df = df.sort_values(\"idf\",ascending=True)\n",
    "\n",
    "tfidf_df = pd.DataFrame({'word': blob1.words, 'tf_idf_doc1': [tfidf(word, blob1, blob_list) for word in blob1.words]})\n",
    "\n",
    "df = pd.merge(df,tfidf_df,on='word',how='outer').drop_duplicates()\n",
    "df_final = df[[\"word\",\"doc1_term_freq\",\"doc1_term_rel_freq\",\"doc_freq\",\"idf\",\"tf_idf_doc1\"]]\n",
    "df_final.sort_values(by=['tf_idf_doc1'], ascending=[False]).head(n=10)\n",
    "df_final.to_csv(\"/users/asheets/Documents/Work_Computer_new/Work_Computer/Grad_School/PREDICT_453/Notebooks/DSI24_tfidf.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf_idf_doc1</th>\n",
       "      <th>tf_idf_doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>energy</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>0.039822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>era</td>\n",
       "      <td>0.034877</td>\n",
       "      <td>0.011385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>future</td>\n",
       "      <td>0.032492</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>coal</td>\n",
       "      <td>0.028441</td>\n",
       "      <td>0.027851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>order</td>\n",
       "      <td>0.027793</td>\n",
       "      <td>0.036289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>emissions</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>0.025455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  tf_idf_doc1  tf_idf_doc2\n",
       "192     energy     0.050831     0.039822\n",
       "266        era     0.034877     0.011385\n",
       "473     future     0.032492          NaN\n",
       "329       coal     0.028441     0.027851\n",
       "122      order     0.027793     0.036289\n",
       "388  emissions     0.025994     0.025455"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Compare just the two articles we know to be similar\n",
    "blob2 = tb(all_documents['noun_phrases_only'][27])\n",
    "term_freq = [tf1(word,blob2) for word in blob2.words]\n",
    "term_rel_freq = [tf2(word,blob2) for word in blob2.words]\n",
    "tf_df2 = pd.DataFrame({'word': blob2.words, 'doc2_term_freq': term_freq, 'doc2_term_rel_freq': term_rel_freq})\n",
    "two_tf = pd.merge(tf_df1,tf_df2,on='word',how='outer').drop_duplicates()\n",
    "\n",
    "docs_containing1 = pd.DataFrame({'word': blob1.words, 'doc_freq': [n_containing(word,bloblist) for word in blob1.words]})\n",
    "docs_containing2 = pd.DataFrame({'word': blob2.words, 'doc_freq': [n_containing(word,bloblist) for word in blob2.words]})\n",
    "\n",
    "doc_freq = pd.concat([docs_containing1,docs_containing2]).drop_duplicates().reset_index(drop=True)\n",
    "df = pd.merge(doc_freq,two_tf,on='word',how='inner')\n",
    "df = df.sort_values(\"doc_freq\",ascending=False)\n",
    "\n",
    "df['intermediate_calc'] = (len(blob_list) / df['doc_freq']).astype(float)\n",
    "df['idf'] = df['intermediate_calc'].apply(math.log)\n",
    "df = df.sort_values(\"idf\",ascending=False)\n",
    "\n",
    "scores1 = pd.DataFrame({'word': blob1.words, 'tf_idf_doc1': [tfidf(word, blob1, blob_list) for word in blob1.words]})\n",
    "scores2 = pd.DataFrame({'word': blob2.words, 'tf_idf_doc2': [tfidf(word, blob2, blob_list) for word in blob2.words]})\n",
    "\n",
    "two_tfidf= pd.merge(scores1,scores2,on='word',how='outer').drop_duplicates()\n",
    "two_tfidf = two_tfidf[['word', 'tf_idf_doc1', 'tf_idf_doc2']]\n",
    "two_tfidf = two_tfidf.sort_values(by=['tf_idf_doc1', 'tf_idf_doc2'], ascending=[False,False])\n",
    "two_tfidf.head(n=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: registry, TF-IDF: 0.06249\n",
      "\tWord: muslim, TF-IDF: 0.05373\n",
      "\tWord: countries, TF-IDF: 0.03303\n",
      "\tWord: immigration, TF-IDF: 0.03204\n",
      "\tWord: source, TF-IDF: 0.03201\n",
      "\tWord: risk, TF-IDF: 0.03201\n",
      "\tWord: ban, TF-IDF: 0.03201\n",
      "\tWord: terrorism, TF-IDF: 0.03125\n",
      "\tWord: muslims, TF-IDF: 0.03125\n",
      "\tWord: database, TF-IDF: 0.03125\n",
      "Top words in document 2\n",
      "\tWord: nuclear, TF-IDF: 0.16595\n",
      "\tWord: arms, TF-IDF: 0.06915\n",
      "\tWord: race, TF-IDF: 0.04756\n",
      "\tWord: proliferation, TF-IDF: 0.04149\n",
      "\tWord: corp, TF-IDF: 0.04149\n",
      "\tWord: uranium, TF-IDF: 0.04149\n",
      "\tWord: treaty, TF-IDF: 0.04149\n",
      "\tWord: friday, TF-IDF: 0.0398\n",
      "\tWord: weapons, TF-IDF: 0.03567\n",
      "\tWord: comments, TF-IDF: 0.03429\n",
      "Top words in document 3\n",
      "\tWord: act, TF-IDF: 0.06712\n",
      "\tWord: infrastructure, TF-IDF: 0.02937\n",
      "\tWord: ban, TF-IDF: 0.02427\n",
      "\tWord: corruption, TF-IDF: 0.02369\n",
      "\tWord: workers, TF-IDF: 0.02203\n",
      "\tWord: american, TF-IDF: 0.02153\n",
      "\tWord: clean, TF-IDF: 0.01849\n",
      "\tWord: education, TF-IDF: 0.01801\n",
      "\tWord: constitutional, TF-IDF: 0.01801\n",
      "\tWord: illegal, TF-IDF: 0.01618\n",
      "Top words in document 4\n",
      "\tWord: tax, TF-IDF: 0.13251\n",
      "\tWord: income, TF-IDF: 0.05682\n",
      "\tWord: rates, TF-IDF: 0.04983\n",
      "\tWord: estate, TF-IDF: 0.03788\n",
      "\tWord: plan, TF-IDF: 0.03557\n",
      "\tWord: stuff, TF-IDF: 0.03213\n",
      "\tWord: rate, TF-IDF: 0.03213\n",
      "\tWord: reform, TF-IDF: 0.03089\n",
      "\tWord: pomerleau, TF-IDF: 0.02492\n",
      "\tWord: valliere, TF-IDF: 0.02492\n",
      "Top words in document 5\n",
      "\tWord: education, TF-IDF: 0.09741\n",
      "\tWord: school, TF-IDF: 0.06454\n",
      "\tWord: choice, TF-IDF: 0.04034\n",
      "\tWord: funds, TF-IDF: 0.04034\n",
      "\tWord: professor, TF-IDF: 0.03247\n",
      "\tWord: schools, TF-IDF: 0.02848\n",
      "\tWord: leaves, TF-IDF: 0.02848\n",
      "\tWord: pres, TF-IDF: 0.02848\n",
      "\tWord: charter, TF-IDF: 0.02448\n",
      "\tWord: families, TF-IDF: 0.02448\n",
      "Top words in document 6\n",
      "\tWord: foundation, TF-IDF: 0.19908\n",
      "\tWord: dissolve, TF-IDF: 0.05071\n",
      "\tWord: conflicts, TF-IDF: 0.04359\n",
      "\tWord: saturday, TF-IDF: 0.03855\n",
      "\tWord: eric, TF-IDF: 0.03855\n",
      "\tWord: interest, TF-IDF: 0.03518\n",
      "\tWord: son, TF-IDF: 0.03381\n",
      "\tWord: charity, TF-IDF: 0.03381\n",
      "\tWord: philanthropic, TF-IDF: 0.03381\n",
      "\tWord: tax, TF-IDF: 0.02996\n",
      "Top words in document 7\n",
      "\tWord: factory, TF-IDF: 0.06982\n",
      "\tWord: ford, TF-IDF: 0.06982\n",
      "\tWord: car, TF-IDF: 0.04802\n",
      "\tWord: mexico, TF-IDF: 0.04777\n",
      "\tWord: mr, TF-IDF: 0.04688\n",
      "\tWord: auto, TF-IDF: 0.04189\n",
      "\tWord: fields, TF-IDF: 0.04189\n",
      "\tWord: michigan, TF-IDF: 0.03601\n",
      "\tWord: trade, TF-IDF: 0.03094\n",
      "\tWord: jobs, TF-IDF: 0.02952\n",
      "Top words in document 8\n",
      "\tWord: trade, TF-IDF: 0.03618\n",
      "\tWord: country, TF-IDF: 0.03202\n",
      "\tWord: percent, TF-IDF: 0.03037\n",
      "\tWord: mexico, TF-IDF: 0.02483\n",
      "\tWord: war, TF-IDF: 0.02025\n",
      "\tWord: full, TF-IDF: 0.0185\n",
      "\tWord: act, TF-IDF: 0.0185\n",
      "\tWord: plan, TF-IDF: 0.01696\n",
      "\tWord: devastate, TF-IDF: 0.01633\n",
      "\tWord: airports, TF-IDF: 0.01633\n",
      "Top words in document 9\n",
      "\tWord: infrastructure, TF-IDF: 0.05931\n",
      "\tWord: bank, TF-IDF: 0.04127\n",
      "\tWord: spending, TF-IDF: 0.03783\n",
      "\tWord: credits, TF-IDF: 0.03525\n",
      "\tWord: projects, TF-IDF: 0.03424\n",
      "\tWord: tax, TF-IDF: 0.02901\n",
      "\tWord: capital, TF-IDF: 0.0268\n",
      "\tWord: objective, TF-IDF: 0.02518\n",
      "\tWord: quality, TF-IDF: 0.02518\n",
      "\tWord: water, TF-IDF: 0.01873\n",
      "Top words in document 10\n",
      "\tWord: court, TF-IDF: 0.07625\n",
      "\tWord: conservative, TF-IDF: 0.0655\n",
      "\tWord: supreme, TF-IDF: 0.05493\n",
      "\tWord: scalia, TF-IDF: 0.04394\n",
      "\tWord: liberal, TF-IDF: 0.04394\n",
      "\tWord: kennedy, TF-IDF: 0.03727\n",
      "\tWord: justice, TF-IDF: 0.03275\n",
      "\tWord: list, TF-IDF: 0.03275\n",
      "\tWord: bloc, TF-IDF: 0.0289\n",
      "\tWord: th, TF-IDF: 0.0289\n",
      "Top words in document 11\n",
      "\tWord: diplomats, TF-IDF: 0.08074\n",
      "\tWord: mr, TF-IDF: 0.06196\n",
      "\tWord: russian, TF-IDF: 0.04574\n",
      "\tWord: putin, TF-IDF: 0.04411\n",
      "\tWord: russia, TF-IDF: 0.03361\n",
      "\tWord: diplomatic, TF-IDF: 0.03229\n",
      "\tWord: response, TF-IDF: 0.03003\n",
      "\tWord: kremlin, TF-IDF: 0.02206\n",
      "\tWord: services, TF-IDF: 0.02206\n",
      "\tWord: intelligence, TF-IDF: 0.02147\n",
      "Top words in document 12\n",
      "\tWord: appropriations, TF-IDF: 0.10983\n",
      "\tWord: budget, TF-IDF: 0.06929\n",
      "\tWord: bills, TF-IDF: 0.06864\n",
      "\tWord: rogers, TF-IDF: 0.06388\n",
      "\tWord: resolution, TF-IDF: 0.04791\n",
      "\tWord: reconciliation, TF-IDF: 0.04119\n",
      "\tWord: major, TF-IDF: 0.03324\n",
      "\tWord: spending, TF-IDF: 0.03272\n",
      "\tWord: gop, TF-IDF: 0.0297\n",
      "\tWord: shot, TF-IDF: 0.02746\n",
      "Top words in document 13\n",
      "\tWord: intelligence, TF-IDF: 0.06495\n",
      "\tWord: russia, TF-IDF: 0.04661\n",
      "\tWord: russian, TF-IDF: 0.02768\n",
      "\tWord: community, TF-IDF: 0.02672\n",
      "\tWord: skepticism, TF-IDF: 0.02443\n",
      "\tWord: assange, TF-IDF: 0.02443\n",
      "\tWord: officials, TF-IDF: 0.02165\n",
      "\tWord: wikileaks, TF-IDF: 0.021\n",
      "\tWord: committee, TF-IDF: 0.01953\n",
      "\tWord: thursday, TF-IDF: 0.01845\n",
      "Top words in document 14\n",
      "\tWord: hotel, TF-IDF: 0.02474\n",
      "\tWord: organization, TF-IDF: 0.02045\n",
      "\tWord: ruffin, TF-IDF: 0.01649\n",
      "\tWord: interest, TF-IDF: 0.01287\n",
      "\tWord: financial, TF-IDF: 0.01278\n",
      "\tWord: saudi, TF-IDF: 0.01237\n",
      "\tWord: deutsche, TF-IDF: 0.01237\n",
      "\tWord: event, TF-IDF: 0.01237\n",
      "\tWord: duterte, TF-IDF: 0.01237\n",
      "\tWord: sajwani, TF-IDF: 0.01237\n",
      "Top words in document 15\n",
      "\tWord: wall, TF-IDF: 0.07832\n",
      "\tWord: taxpayer, TF-IDF: 0.06692\n",
      "\tWord: mr, TF-IDF: 0.04699\n",
      "\tWord: border, TF-IDF: 0.04699\n",
      "\tWord: barrier, TF-IDF: 0.04212\n",
      "\tWord: dollars, TF-IDF: 0.04049\n",
      "\tWord: building, TF-IDF: 0.04049\n",
      "\tWord: bills, TF-IDF: 0.02808\n",
      "\tWord: appropriations, TF-IDF: 0.02808\n",
      "\tWord: billions, TF-IDF: 0.02808\n",
      "Top words in document 16\n",
      "\tWord: server, TF-IDF: 0.13465\n",
      "\tWord: emails, TF-IDF: 0.09741\n",
      "\tWord: clinton, TF-IDF: 0.07035\n",
      "\tWord: email, TF-IDF: 0.04446\n",
      "\tWord: department, TF-IDF: 0.04313\n",
      "\tWord: thumb, TF-IDF: 0.04271\n",
      "\tWord: boehner, TF-IDF: 0.04271\n",
      "\tWord: aide, TF-IDF: 0.04271\n",
      "\tWord: drive, TF-IDF: 0.04271\n",
      "\tWord: evening, TF-IDF: 0.03672\n",
      "Top words in document 17\n",
      "\tWord: city, TF-IDF: 0.03576\n",
      "\tWord: state, TF-IDF: 0.02691\n",
      "\tWord: gov, TF-IDF: 0.02613\n",
      "\tWord: mayors, TF-IDF: 0.02091\n",
      "\tWord: california, TF-IDF: 0.02073\n",
      "\tWord: democratic, TF-IDF: 0.01853\n",
      "\tWord: mayor, TF-IDF: 0.01797\n",
      "\tWord: phoenix, TF-IDF: 0.01797\n",
      "\tWord: opposition, TF-IDF: 0.01785\n",
      "\tWord: york, TF-IDF: 0.01589\n",
      "Top words in document 18\n",
      "\tWord: border, TF-IDF: 0.06762\n",
      "\tWord: miles, TF-IDF: 0.06699\n",
      "\tWord: wall, TF-IDF: 0.04227\n",
      "\tWord: lawmakers, TF-IDF: 0.03611\n",
      "\tWord: double, TF-IDF: 0.03525\n",
      "\tWord: aides, TF-IDF: 0.0303\n",
      "\tWord: barrier, TF-IDF: 0.0303\n",
      "\tWord: physical, TF-IDF: 0.0303\n",
      "\tWord: fence, TF-IDF: 0.0268\n",
      "\tWord: southern, TF-IDF: 0.0268\n",
      "Top words in document 19\n",
      "\tWord: coal, TF-IDF: 0.04283\n",
      "\tWord: ier, TF-IDF: 0.0403\n",
      "\tWord: oil, TF-IDF: 0.03926\n",
      "\tWord: energy, TF-IDF: 0.03572\n",
      "\tWord: pipeline, TF-IDF: 0.02498\n",
      "\tWord: study, TF-IDF: 0.02475\n",
      "\tWord: atlantic, TF-IDF: 0.02303\n",
      "\tWord: production, TF-IDF: 0.02284\n",
      "\tWord: fuel, TF-IDF: 0.02142\n",
      "\tWord: coast, TF-IDF: 0.0198\n",
      "Top words in document 20\n",
      "\tWord: energy, TF-IDF: 0.05822\n",
      "\tWord: epa, TF-IDF: 0.05608\n",
      "\tWord: rule, TF-IDF: 0.03745\n",
      "\tWord: interior, TF-IDF: 0.03285\n",
      "\tWord: paris, TF-IDF: 0.03054\n",
      "\tWord: likely, TF-IDF: 0.02564\n",
      "\tWord: targets, TF-IDF: 0.02497\n",
      "\tWord: agreement, TF-IDF: 0.02363\n",
      "\tWord: power, TF-IDF: 0.02315\n",
      "\tWord: means, TF-IDF: 0.02243\n",
      "Top words in document 21\n",
      "\tWord: china, TF-IDF: 0.08408\n",
      "\tWord: paris, TF-IDF: 0.04497\n",
      "\tWord: chinese, TF-IDF: 0.03358\n",
      "\tWord: climate, TF-IDF: 0.03204\n",
      "\tWord: energy, TF-IDF: 0.0272\n",
      "\tWord: world, TF-IDF: 0.02676\n",
      "\tWord: commitment, TF-IDF: 0.01919\n",
      "\tWord: iea, TF-IDF: 0.01674\n",
      "\tWord: xi, TF-IDF: 0.01674\n",
      "\tWord: countries, TF-IDF: 0.01573\n",
      "Top words in document 22\n",
      "\tWord: russia, TF-IDF: 0.06207\n",
      "\tWord: priebus, TF-IDF: 0.05505\n",
      "\tWord: cyber, TF-IDF: 0.04733\n",
      "\tWord: putin, TF-IDF: 0.0376\n",
      "\tWord: intelligence, TF-IDF: 0.03253\n",
      "\tWord: attacks, TF-IDF: 0.02507\n",
      "\tWord: expert, TF-IDF: 0.02367\n",
      "\tWord: sunday, TF-IDF: 0.02275\n",
      "\tWord: election, TF-IDF: 0.02258\n",
      "\tWord: russian, TF-IDF: 0.0208\n",
      "Top words in document 23\n",
      "\tWord: news, TF-IDF: 0.08451\n",
      "\tWord: fake, TF-IDF: 0.05484\n",
      "\tWord: document, TF-IDF: 0.05018\n",
      "\tWord: press, TF-IDF: 0.0494\n",
      "\tWord: cnn, TF-IDF: 0.04549\n",
      "\tWord: journalism, TF-IDF: 0.04014\n",
      "\tWord: outlets, TF-IDF: 0.03052\n",
      "\tWord: acosta, TF-IDF: 0.03011\n",
      "\tWord: conference, TF-IDF: 0.02843\n",
      "\tWord: media, TF-IDF: 0.02489\n",
      "Top words in document 24\n",
      "\tWord: energy, TF-IDF: 0.05083\n",
      "\tWord: era, TF-IDF: 0.03488\n",
      "\tWord: future, TF-IDF: 0.03249\n",
      "\tWord: coal, TF-IDF: 0.02844\n",
      "\tWord: order, TF-IDF: 0.02779\n",
      "\tWord: emissions, TF-IDF: 0.02599\n",
      "\tWord: clean, TF-IDF: 0.02387\n",
      "\tWord: environmental, TF-IDF: 0.02352\n",
      "\tWord: regulations, TF-IDF: 0.02352\n",
      "\tWord: creation, TF-IDF: 0.02294\n",
      "Top words in document 25\n",
      "\tWord: q, TF-IDF: 0.09483\n",
      "\tWord: mr, TF-IDF: 0.06004\n",
      "\tWord: spicer, TF-IDF: 0.05913\n",
      "\tWord: vote, TF-IDF: 0.02638\n",
      "\tWord: healthcare, TF-IDF: 0.01957\n",
      "\tWord: lot, TF-IDF: 0.01554\n",
      "\tWord: bill, TF-IDF: 0.01546\n",
      "\tWord: reform, TF-IDF: 0.01411\n",
      "\tWord: members, TF-IDF: 0.01397\n",
      "\tWord: morning, TF-IDF: 0.01397\n",
      "Top words in document 26\n",
      "\tWord: fbi, TF-IDF: 0.05776\n",
      "\tWord: steele, TF-IDF: 0.05472\n",
      "\tWord: russia, TF-IDF: 0.03883\n",
      "\tWord: intelligence, TF-IDF: 0.03087\n",
      "\tWord: cia, TF-IDF: 0.02994\n",
      "\tWord: investigation, TF-IDF: 0.02647\n",
      "\tWord: co, TF-IDF: 0.02566\n",
      "\tWord: kalugin, TF-IDF: 0.02487\n",
      "\tWord: dossier, TF-IDF: 0.02487\n",
      "\tWord: diplomat, TF-IDF: 0.02487\n",
      "Top words in document 27\n",
      "\tWord: homeland, TF-IDF: 0.06661\n",
      "\tWord: subsection, TF-IDF: 0.06447\n",
      "\tWord: section, TF-IDF: 0.05718\n",
      "\tWord: nationals, TF-IDF: 0.05372\n",
      "\tWord: submit, TF-IDF: 0.05372\n",
      "\tWord: security, TF-IDF: 0.04922\n",
      "\tWord: date, TF-IDF: 0.04901\n",
      "\tWord: effective, TF-IDF: 0.04901\n",
      "\tWord: consultation, TF-IDF: 0.04298\n",
      "\tWord: secretary, TF-IDF: 0.03933\n",
      "Top words in document 28\n",
      "\tWord: energy, TF-IDF: 0.03982\n",
      "\tWord: clean, TF-IDF: 0.03897\n",
      "\tWord: order, TF-IDF: 0.03629\n",
      "\tWord: power, TF-IDF: 0.03167\n",
      "\tWord: climate, TF-IDF: 0.03072\n",
      "\tWord: environmental, TF-IDF: 0.03072\n",
      "\tWord: activist, TF-IDF: 0.02995\n",
      "\tWord: paris, TF-IDF: 0.02785\n",
      "\tWord: coal, TF-IDF: 0.02785\n",
      "\tWord: undo, TF-IDF: 0.02575\n",
      "Top words in document 29\n",
      "\tWord: fcc, TF-IDF: 0.07411\n",
      "\tWord: internet, TF-IDF: 0.06761\n",
      "\tWord: isps, TF-IDF: 0.05929\n",
      "\tWord: information, TF-IDF: 0.05255\n",
      "\tWord: data, TF-IDF: 0.04507\n",
      "\tWord: privacy, TF-IDF: 0.04447\n",
      "\tWord: users, TF-IDF: 0.04447\n",
      "\tWord: advocates, TF-IDF: 0.03823\n",
      "\tWord: history, TF-IDF: 0.0338\n",
      "\tWord: rules, TF-IDF: 0.03284\n",
      "Top words in document 30\n",
      "\tWord: border, TF-IDF: 0.04673\n",
      "\tWord: km, TF-IDF: 0.04653\n",
      "\tWord: miles, TF-IDF: 0.04115\n",
      "\tWord: report, TF-IDF: 0.03996\n",
      "\tWord: construction, TF-IDF: 0.0368\n",
      "\tWord: texas, TF-IDF: 0.03355\n",
      "\tWord: dhs, TF-IDF: 0.02792\n",
      "\tWord: reuters, TF-IDF: 0.02469\n",
      "\tWord: mexico, TF-IDF: 0.02469\n",
      "\tWord: estimates, TF-IDF: 0.02218\n",
      "Top words in document 31\n",
      "\tWord: trade, TF-IDF: 0.12258\n",
      "\tWord: deficit, TF-IDF: 0.07134\n",
      "\tWord: navarro, TF-IDF: 0.05945\n",
      "\tWord: japan, TF-IDF: 0.04756\n",
      "\tWord: nations, TF-IDF: 0.04205\n",
      "\tWord: china, TF-IDF: 0.03677\n",
      "\tWord: deficits, TF-IDF: 0.03567\n",
      "\tWord: bilateral, TF-IDF: 0.03567\n",
      "\tWord: mr, TF-IDF: 0.03316\n",
      "\tWord: hegemony, TF-IDF: 0.02766\n",
      "Top words in document 32\n",
      "\tWord: small, TF-IDF: 0.07695\n",
      "\tWord: korzenik, TF-IDF: 0.07093\n",
      "\tWord: toledo, TF-IDF: 0.0532\n",
      "\tWord: business, TF-IDF: 0.04374\n",
      "\tWord: owner, TF-IDF: 0.03546\n",
      "\tWord: mr, TF-IDF: 0.03402\n",
      "\tWord: confidence, TF-IDF: 0.03298\n",
      "\tWord: lunch, TF-IDF: 0.03049\n",
      "\tWord: care, TF-IDF: 0.03014\n",
      "\tWord: businesses, TF-IDF: 0.02422\n",
      "Top words in document 33\n",
      "\tWord: budget, TF-IDF: 0.10156\n",
      "\tWord: cuts, TF-IDF: 0.03558\n",
      "\tWord: mulvaney, TF-IDF: 0.03511\n",
      "\tWord: bn, TF-IDF: 0.03511\n",
      "\tWord: programs, TF-IDF: 0.03511\n",
      "\tWord: aid, TF-IDF: 0.02669\n",
      "\tWord: proposal, TF-IDF: 0.02436\n",
      "\tWord: epa, TF-IDF: 0.02398\n",
      "\tWord: dead, TF-IDF: 0.0234\n",
      "\tWord: pentagon, TF-IDF: 0.0234\n",
      "Top words in document 34\n",
      "\tWord: robart, TF-IDF: 0.12489\n",
      "\tWord: judge, TF-IDF: 0.10737\n",
      "\tWord: mr, TF-IDF: 0.06846\n",
      "\tWord: ban, TF-IDF: 0.04874\n",
      "\tWord: check, TF-IDF: 0.04602\n",
      "\tWord: independent, TF-IDF: 0.04069\n",
      "\tWord: appointee, TF-IDF: 0.03568\n",
      "\tWord: tweets, TF-IDF: 0.03068\n",
      "\tWord: gorsuch, TF-IDF: 0.03068\n",
      "\tWord: travel, TF-IDF: 0.03068\n",
      "Top words in document 36\n",
      "\tWord: flemings, TF-IDF: 0.09384\n",
      "\tWord: irs, TF-IDF: 0.06454\n",
      "\tWord: date, TF-IDF: 0.05707\n",
      "\tWord: austin, TF-IDF: 0.05631\n",
      "\tWord: job, TF-IDF: 0.04991\n",
      "\tWord: january, TF-IDF: 0.04841\n",
      "\tWord: sessions, TF-IDF: 0.03754\n",
      "\tWord: intake, TF-IDF: 0.03754\n",
      "\tWord: sic, TF-IDF: 0.03754\n",
      "\tWord: omb, TF-IDF: 0.03227\n",
      "Top words in document 39\n",
      "\tWord: gorsuch, TF-IDF: 0.11582\n",
      "\tWord: court, TF-IDF: 0.04699\n",
      "\tWord: r, TF-IDF: 0.04182\n",
      "\tWord: confirmation, TF-IDF: 0.03724\n",
      "\tWord: supreme, TF-IDF: 0.03724\n",
      "\tWord: filibuster, TF-IDF: 0.03674\n",
      "\tWord: judge, TF-IDF: 0.03159\n",
      "\tWord: nominees, TF-IDF: 0.03159\n",
      "\tWord: hearings, TF-IDF: 0.03159\n",
      "\tWord: republicans, TF-IDF: 0.03021\n"
     ]
    }
   ],
   "source": [
    "#compare all DSIs sing all pre-defined functions\n",
    "DSI_list = all_documents[\"DSInum\"]\n",
    "for i, blob in enumerate(blob_list):\n",
    "    print(\"Top words in document {}\".format(DSI_list[i]))\n",
    "    scores = {word: tfidf(word, blob, blob_list) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-54af94d778b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mnew_tf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_tf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnew_tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#new_tf.to_csv(\"RTV_frequencies2.txt\", sep='\\t')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asheets/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2414\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asheets/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_setitem_frame\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_inplace_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2453\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2454\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asheets/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_where\u001b[0;34m(self, cond, other, inplace, axis, level, try_cast, raise_on_error)\u001b[0m\n\u001b[1;32m   4699\u001b[0m             new_data = self._data.putmask(mask=cond, new=other, align=align,\n\u001b[1;32m   4700\u001b[0m                                           \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4701\u001b[0;31m                                           transpose=self._AXIS_REVERSED)\n\u001b[0m\u001b[1;32m   4702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asheets/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mputmask\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'putmask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asheets/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3051\u001b[0m                     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_info_axis_number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m                     kwargs[k] = obj.reindex_axis(b_items, axis=axis,\n\u001b[0;32m-> 3053\u001b[0;31m                                                  copy=align_copy)\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asheets/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mreindex_axis\u001b[0;34m(self, labels, axis, method, level, copy, limit, fill_value)\u001b[0m\n\u001b[1;32m   2827\u001b[0m                      \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m                                         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m                                         limit=limit, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asheets/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mreindex_axis\u001b[0;34m(self, labels, axis, method, level, copy, limit, fill_value)\u001b[0m\n\u001b[1;32m   2346\u001b[0m                                                  limit=limit)\n\u001b[1;32m   2347\u001b[0m         return self._reindex_with_indexers({axis: [new_index, indexer]},\n\u001b[0;32m-> 2348\u001b[0;31m                                            fill_value=fill_value, copy=copy)\n\u001b[0m\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2350\u001b[0m     def _reindex_with_indexers(self, reindexers, fill_value=np.nan, copy=False,\n",
      "\u001b[0;32m/Users/asheets/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   2369\u001b[0m                                                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                                                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m                                                 copy=copy)\n\u001b[0m\u001b[1;32m   2372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asheets/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   3837\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3839\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asheets/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   2492\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "RTV = pd.read_csv('RTV.txt',header=None)\n",
    "RTV.columns = ['word']\n",
    "\n",
    "RTVblob = tb(str(tuple(RTV.word.tolist())).replace(\"'\", \"\"))\n",
    "RTV_final = list(RTV['word'])\n",
    "\n",
    "tf_list = []\n",
    "\n",
    "for i, blob in enumerate(blob_list):\n",
    "    for item in RTV_final:\n",
    "        tf_list.append({'DSInum': DSI_list[i], 'word': item, 'term_freq': blob.words.count(item)})\n",
    "\n",
    "#print pd.DataFrame(tf_list)\n",
    "tf_df = pd.DataFrame(tf_list)\n",
    "tf_df.to_csv(\"RTV_frequencies.txt\", sep='\\t')\n",
    "\n",
    "new_tf = tf_df[tf_df['DSInum'] == 24]\n",
    "new_tf = new_tf[[\"word\",\"term_freq\"]]\n",
    "\n",
    "for i in range(1,36):\n",
    "    try:\n",
    "        tmp = tf_df[tf_df['DSInum'] == DSI_list[i]]\n",
    "        tmp = tmp[[\"word\",\"term_freq\"]]\n",
    "        new_tf = pd.merge(new_tf, tmp, on='word', how='outer')\n",
    "    except IOError:\n",
    "        pass  \n",
    "\n",
    "new_tf[new_tf == 0] = numpy.NaN\n",
    "print new_tf\n",
    "#new_tf.to_csv(\"RTV_frequencies2.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     24\n",
      "1     25\n",
      "2     26\n",
      "3     27\n",
      "4     28\n",
      "5     29\n",
      "6     30\n",
      "7     31\n",
      "8     32\n",
      "9     33\n",
      "10    34\n",
      "11    36\n",
      "12    39\n",
      "Name: DSInum, dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
