{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob as tb\n",
    "import math\n",
    "import io\n",
    "from __future__ import division\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "os.chdir('/users/asheets/Documents/Work_Computer_new/Work_Computer/Grad_School/PREDICT_453/Notebooks/DSI/')\n",
    "\n",
    "all_docs = []\n",
    "dsis = []\n",
    "d = 1\n",
    "\n",
    "cachedStopWords = nltk.corpus.stopwords.words('english')\n",
    "pattern = re.compile(r'\\b(' + r'|'.join(cachedStopWords) + r')\\b\\s*')\n",
    "\n",
    "for i in range(40):\n",
    "    doc_name = 'DSI' + str(d) + '.txt'\n",
    "    try:\n",
    "        with open(doc_name, 'r') as f:\n",
    "            sample = f.read()\n",
    "        sample = sample.decode('utf-8')\n",
    "       #sample = sample.decode('ascii')\n",
    "        sample = sample.lower()\n",
    "        sample = re.sub(r'[^\\w]', ' ', sample)\n",
    "        sample = ''.join([i for i in sample if not i.isdigit()])\n",
    "        sample = pattern.sub('', sample)\n",
    "        sample = \"\".join(l for l in sample if l not in string.punctuation)\n",
    "        sample2 = \" \".join(k for k in tb(sample).noun_phrases)\n",
    "        all_docs.append(sample)\n",
    "        dsis.append('DSI' + str(d))\n",
    "        d = d + 1\n",
    "    except IOError:\n",
    "        d = d + 1\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Using resource: http://brandonrose.org/clustering\n",
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 789 ms, sys: 19.5 ms, total: 809 ms\n",
      "Wall time: 869 ms\n",
      "(38, 318)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(all_docs) #fit the vectorizer to all_docs\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'accord',\n",
       " u'act',\n",
       " u'action',\n",
       " u'ad',\n",
       " u'addit',\n",
       " u'address',\n",
       " u'afford',\n",
       " u'agenc',\n",
       " u'agre',\n",
       " u'agreement',\n",
       " u'allow',\n",
       " u'alreadi',\n",
       " u'america',\n",
       " u'american',\n",
       " u'announc',\n",
       " u'anoth',\n",
       " u'appear',\n",
       " u'approv',\n",
       " u'argu',\n",
       " u'ask',\n",
       " u'associ',\n",
       " u'attempt',\n",
       " u'author',\n",
       " u'barack',\n",
       " u'barack obama',\n",
       " u'base',\n",
       " u'begin',\n",
       " u'believ',\n",
       " u'benefit',\n",
       " u'better',\n",
       " u'big',\n",
       " u'billion',\n",
       " u'border',\n",
       " u'build',\n",
       " u'busi',\n",
       " u'c',\n",
       " u'campaign',\n",
       " u'care',\n",
       " u'case',\n",
       " u'chairman',\n",
       " u'chang',\n",
       " u'china',\n",
       " u'choic',\n",
       " u'claim',\n",
       " u'clean',\n",
       " u'clear',\n",
       " u'climat',\n",
       " u'climat chang',\n",
       " u'clinton',\n",
       " u'close',\n",
       " u'come',\n",
       " u'comment',\n",
       " u'committe',\n",
       " u'communiti',\n",
       " u'compani',\n",
       " u'competit',\n",
       " u'complet',\n",
       " u'concern',\n",
       " u'confirm',\n",
       " u'congress',\n",
       " u'congression',\n",
       " u'conserv',\n",
       " u'consid',\n",
       " u'construct',\n",
       " u'continu',\n",
       " u'control',\n",
       " u'cost',\n",
       " u'countri',\n",
       " u'court',\n",
       " u'creat',\n",
       " u'critic',\n",
       " u'current',\n",
       " u'cut',\n",
       " u'day',\n",
       " u'deal',\n",
       " u'decis',\n",
       " u'democrat',\n",
       " u'depart',\n",
       " u'develop',\n",
       " u'direct',\n",
       " u'director',\n",
       " u'discuss',\n",
       " u'domest',\n",
       " u'donald',\n",
       " u'donald trump',\n",
       " u'earli',\n",
       " u'econom',\n",
       " u'economi',\n",
       " u'effect',\n",
       " u'effort',\n",
       " u'elect',\n",
       " u'elect donald',\n",
       " u'elect donald trump',\n",
       " u'email',\n",
       " u'end',\n",
       " u'energi',\n",
       " u'entir',\n",
       " u'environment',\n",
       " u'everi',\n",
       " u'evid',\n",
       " u'execut',\n",
       " u'expect',\n",
       " u'expert',\n",
       " u'face',\n",
       " u'fact',\n",
       " u'far',\n",
       " u'feder',\n",
       " u'fight',\n",
       " u'final',\n",
       " u'focus',\n",
       " u'follow',\n",
       " u'foreign',\n",
       " u'free',\n",
       " u'friday',\n",
       " u'fund',\n",
       " u'futur',\n",
       " u'general',\n",
       " u'generat',\n",
       " u'global',\n",
       " u'good',\n",
       " u'govern',\n",
       " u'great',\n",
       " u'group',\n",
       " u'grow',\n",
       " u'growth',\n",
       " u'hard',\n",
       " u'head',\n",
       " u'health',\n",
       " u'hear',\n",
       " u'help',\n",
       " u'high',\n",
       " u'hous',\n",
       " u'howev',\n",
       " u'identifi',\n",
       " u'immedi',\n",
       " u'immigr',\n",
       " u'impact',\n",
       " u'import',\n",
       " u'includ',\n",
       " u'incom',\n",
       " u'increas',\n",
       " u'independ',\n",
       " u'individu',\n",
       " u'industri',\n",
       " u'inform',\n",
       " u'initi',\n",
       " u'institut',\n",
       " u'intellig',\n",
       " u'intern',\n",
       " u'interview',\n",
       " u'invest',\n",
       " u'involv',\n",
       " u'issu',\n",
       " u'job',\n",
       " u'john',\n",
       " u'land',\n",
       " u'larg',\n",
       " u'late',\n",
       " u'later',\n",
       " u'law',\n",
       " u'leader',\n",
       " u'legal',\n",
       " u'level',\n",
       " u'like',\n",
       " u'line',\n",
       " u'live',\n",
       " u'long',\n",
       " u'look',\n",
       " u'major',\n",
       " u'make',\n",
       " u'mani',\n",
       " u'mean',\n",
       " u'measur',\n",
       " u'meet',\n",
       " u'member',\n",
       " u'messag',\n",
       " u'mexico',\n",
       " u'million',\n",
       " u'money',\n",
       " u'month',\n",
       " u'mr',\n",
       " u'n',\n",
       " u'nation',\n",
       " u'natur',\n",
       " u'near',\n",
       " u'need',\n",
       " u'negoti',\n",
       " u'new',\n",
       " u'new york',\n",
       " u'news',\n",
       " u'north',\n",
       " u'note',\n",
       " u'number',\n",
       " u'obama',\n",
       " u'obama administr',\n",
       " u'octob',\n",
       " u'offer',\n",
       " u'offic',\n",
       " u'offici',\n",
       " u'open',\n",
       " u'order',\n",
       " u'organ',\n",
       " u'parti',\n",
       " u'pass',\n",
       " u'pay',\n",
       " u'peopl',\n",
       " u'person',\n",
       " u'place',\n",
       " u'plan',\n",
       " u'pledg',\n",
       " u'point',\n",
       " u'polici',\n",
       " u'polit',\n",
       " u'posit',\n",
       " u'possibl',\n",
       " u'potenti',\n",
       " u'power',\n",
       " u'presid elect',\n",
       " u'presid elect donald',\n",
       " u'presidenti',\n",
       " u'press',\n",
       " u'price',\n",
       " u'privat',\n",
       " u'process',\n",
       " u'product',\n",
       " u'program',\n",
       " u'project',\n",
       " u'promis',\n",
       " u'propos',\n",
       " u'protect',\n",
       " u'provid',\n",
       " u'public',\n",
       " u'pull',\n",
       " u'push',\n",
       " u'question',\n",
       " u'quick',\n",
       " u'rais',\n",
       " u'receiv',\n",
       " u'recent',\n",
       " u'reduc',\n",
       " u'regul',\n",
       " u'relat',\n",
       " u'relationship',\n",
       " u'remain',\n",
       " u'repeal',\n",
       " u'report',\n",
       " u'repres',\n",
       " u'republican',\n",
       " u'requir',\n",
       " u'respons',\n",
       " u'result',\n",
       " u'right',\n",
       " u'rule',\n",
       " u'said statement',\n",
       " u'say',\n",
       " u'sean',\n",
       " u'second',\n",
       " u'secretari',\n",
       " u'secur',\n",
       " u'seek',\n",
       " u'seen',\n",
       " u'senat',\n",
       " u'senior',\n",
       " u'servic',\n",
       " u'set',\n",
       " u'sever',\n",
       " u'sign',\n",
       " u'signific',\n",
       " u'similar',\n",
       " u'sinc',\n",
       " u'sourc',\n",
       " u'spend',\n",
       " u'spicer',\n",
       " u'start',\n",
       " u'state',\n",
       " u'statement',\n",
       " u'step',\n",
       " u'stop',\n",
       " u'subject',\n",
       " u'suggest',\n",
       " u'support',\n",
       " u'talk',\n",
       " u'target',\n",
       " u'tax',\n",
       " u'team',\n",
       " u'term',\n",
       " u'thing',\n",
       " u'think',\n",
       " u'time',\n",
       " u'today',\n",
       " u'told',\n",
       " u'trade',\n",
       " u'transit',\n",
       " u'tri',\n",
       " u'trump administr',\n",
       " u'trump said',\n",
       " u'tuesday',\n",
       " u'tweet',\n",
       " u'twitter',\n",
       " u'u',\n",
       " u'unit',\n",
       " u'unit state',\n",
       " u'use',\n",
       " u'vice',\n",
       " u'vice presid',\n",
       " u'vote',\n",
       " u'vow',\n",
       " u'wall',\n",
       " u'want',\n",
       " u'washington',\n",
       " u'way',\n",
       " u'week',\n",
       " u'white',\n",
       " u'white hous',\n",
       " u'win',\n",
       " u'work',\n",
       " u'world',\n",
       " u'york']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.22044605e-16   7.58817823e-01   7.50561818e-01 ...,   8.63109036e-01\n",
      "    8.71101928e-01   9.03437621e-01]\n",
      " [  7.58817823e-01   0.00000000e+00   7.89780964e-01 ...,   8.41992185e-01\n",
      "    8.03234972e-01   9.13070580e-01]\n",
      " [  7.50561818e-01   7.89780964e-01  -2.22044605e-16 ...,   7.84435237e-01\n",
      "    7.61196456e-01   9.18665379e-01]\n",
      " ..., \n",
      " [  8.63109036e-01   8.41992185e-01   7.84435237e-01 ...,  -2.22044605e-16\n",
      "    9.01100246e-01   8.64179997e-01]\n",
      " [  8.71101928e-01   8.03234972e-01   7.61196456e-01 ...,   9.01100246e-01\n",
      "    0.00000000e+00   9.52677042e-01]\n",
      " [  9.03437621e-01   9.13070580e-01   9.18665379e-01 ...,   8.64179997e-01\n",
      "    9.52677042e-01   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 181 ms, sys: 10.4 ms, total: 192 ms\n",
      "Wall time: 232 ms\n"
     ]
    }
   ],
   "source": [
    "#kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DSI</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSI1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSI3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSI4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSI5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSI6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSI7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSI8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSI9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSI12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSI14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSI15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSI16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSI17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSI18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSI19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSI20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSI21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSI23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSI24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSI27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSI28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSI30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSI31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSI33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI35</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSI36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSI37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSI39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DSI  cluster\n",
       "1   DSI1        1\n",
       "4   DSI2        4\n",
       "3   DSI3        3\n",
       "1   DSI4        1\n",
       "3   DSI5        3\n",
       "1   DSI6        1\n",
       "0   DSI7        0\n",
       "0   DSI8        0\n",
       "2   DSI9        2\n",
       "4  DSI10        4\n",
       "4  DSI11        4\n",
       "2  DSI12        2\n",
       "4  DSI13        4\n",
       "1  DSI14        1\n",
       "2  DSI15        2\n",
       "1  DSI16        1\n",
       "1  DSI17        1\n",
       "2  DSI18        2\n",
       "3  DSI19        3\n",
       "3  DSI20        3\n",
       "0  DSI21        0\n",
       "4  DSI22        4\n",
       "1  DSI23        1\n",
       "3  DSI24        3\n",
       "4  DSI25        4\n",
       "4  DSI26        4\n",
       "3  DSI27        3\n",
       "3  DSI28        3\n",
       "4  DSI29        4\n",
       "2  DSI30        2\n",
       "0  DSI31        0\n",
       "4  DSI32        4\n",
       "2  DSI33        2\n",
       "4  DSI34        4\n",
       "4  DSI35        4\n",
       "3  DSI36        3\n",
       "0  DSI37        0\n",
       "4  DSI39        4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSIs = { 'DSI': dsis, 'doc': all_docs, 'cluster': clusters }\n",
    "\n",
    "frame = pd.DataFrame(DSIs, index = [clusters] , columns = ['DSI', 'cluster'])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
