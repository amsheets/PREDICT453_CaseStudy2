{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob as tb\n",
    "import math\n",
    "import io\n",
    "import codecs\n",
    "from __future__ import division\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DSInum</th>\n",
       "      <th>noun_phrases_only</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>president trump executive order american energ...</td>\n",
       "      <td>president trump executive order american energ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>mr spicer good afternoon briefer side morning ...</td>\n",
       "      <td>mr  spicer   good afternoon  everyone   lot go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>report kremlin involvement donald trump electi...</td>\n",
       "      <td>bbc learned us officials  verified  key claim ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>temporary suspension entry nationals countries...</td>\n",
       "      <td>sec     temporary suspension entry nationals c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>president donald trump executive order tuesday...</td>\n",
       "      <td>president donald trump signed executive order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>internet service providers internet history se...</td>\n",
       "      <td>internet service providers may soon able sell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>president donald trump wall u mexico border se...</td>\n",
       "      <td>president donald trump wall  along u mexico bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>trump administration plans press japan germany...</td>\n",
       "      <td>trump administration plans press japan  german...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>toledo ohio cream small business community lun...</td>\n",
       "      <td>toledo  ohio   cream small business community ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33</td>\n",
       "      <td>donald trump tn budget thursday federal govern...</td>\n",
       "      <td>donald trump unveiled tn budget thursday  far ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34</td>\n",
       "      <td>president trump morning twitter offensive fede...</td>\n",
       "      <td>president trump launched early morning twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>long trips austin home new braunfels texas bac...</td>\n",
       "      <td>months waiting hour long trips austin home new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39</td>\n",
       "      <td>judge neil gorsuch u supreme court head week c...</td>\n",
       "      <td>battle confirm judge neil gorsuch u supreme co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DSInum                                  noun_phrases_only  \\\n",
       "0       24  president trump executive order american energ...   \n",
       "1       25  mr spicer good afternoon briefer side morning ...   \n",
       "2       26  report kremlin involvement donald trump electi...   \n",
       "3       27  temporary suspension entry nationals countries...   \n",
       "4       28  president donald trump executive order tuesday...   \n",
       "5       29  internet service providers internet history se...   \n",
       "6       30  president donald trump wall u mexico border se...   \n",
       "7       31  trump administration plans press japan germany...   \n",
       "8       32  toledo ohio cream small business community lun...   \n",
       "9       33  donald trump tn budget thursday federal govern...   \n",
       "10      34  president trump morning twitter offensive fede...   \n",
       "11      36  long trips austin home new braunfels texas bac...   \n",
       "12      39  judge neil gorsuch u supreme court head week c...   \n",
       "\n",
       "                                             raw_text  \n",
       "0   president trump executive order american energ...  \n",
       "1   mr  spicer   good afternoon  everyone   lot go...  \n",
       "2   bbc learned us officials  verified  key claim ...  \n",
       "3   sec     temporary suspension entry nationals c...  \n",
       "4   president donald trump signed executive order ...  \n",
       "5   internet service providers may soon able sell ...  \n",
       "6   president donald trump wall  along u mexico bo...  \n",
       "7   trump administration plans press japan  german...  \n",
       "8   toledo  ohio   cream small business community ...  \n",
       "9   donald trump unveiled tn budget thursday  far ...  \n",
       "10  president trump launched early morning twitter...  \n",
       "11  months waiting hour long trips austin home new...  \n",
       "12  battle confirm judge neil gorsuch u supreme co...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "os.chdir('/users/asheets/Documents/Work_Computer_new/Work_Computer/Grad_School/PREDICT_453/Notebooks/DSI/')\n",
    "\n",
    "all_docs = []\n",
    "blob_list = []\n",
    "d = 24\n",
    "\n",
    "cachedStopWords = nltk.corpus.stopwords.words('english')\n",
    "pattern = re.compile(r'\\b(' + r'|'.join(cachedStopWords) + r')\\b\\s*')\n",
    "\n",
    "for i in range(16):\n",
    "    doc_name = 'DSI' + str(d) + '.txt'\n",
    "    try:\n",
    "        with open(doc_name, 'r') as f:\n",
    "            sample = f.read()\n",
    "        sample = sample.decode('utf-8')\n",
    "       #sample = sample.decode('ascii')\n",
    "        sample = sample.lower()\n",
    "        sample = re.sub(r'[^\\w]', ' ', sample)\n",
    "        sample = ''.join([i for i in sample if not i.isdigit()])\n",
    "        sample = pattern.sub('', sample)\n",
    "        sample = \"\".join(l for l in sample if l not in string.punctuation)\n",
    "        sample2 = \" \".join(k for k in tb(sample).noun_phrases)\n",
    "        all_docs.append({'DSInum': d, 'raw_text': sample, 'noun_phrases_only':\n",
    "        sample2})\n",
    "        blob_list.append(tb(sample2))\n",
    "        d = d + 1\n",
    "    except IOError:\n",
    "        d = d + 1\n",
    "        pass\n",
    "    \n",
    "all_documents = pd.DataFrame(all_docs)\n",
    "    \n",
    "RTV = pd.read_csv('RTV.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#http://stevenloria.com/finding-important-words-in-a-document-using-tf-idf/\n",
    "\n",
    "#computes \"term frequency\" which is the number of times a word appears in a document blob, \n",
    "#normalized by dividing by the total number of words in blob. \n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "#returns the number of documents containing word. A generator expression is passed to the sum() function.\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "#computes \"inverse document frequency\" which measures how common a word is among all documents in bloblist. \n",
    "#The more common a word is, the lower its idf. \n",
    "#We take the ratio of the total number of documents to the number of documents containing word, \n",
    "#then take the log of that. Add 1 to the divisor to prevent division by zero.\n",
    "def idf(word, bloblist):\n",
    "     return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "#computes the TF-IDF score. It is simply the product of  tf and idf.\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf_idf_doc1</th>\n",
       "      <th>tf_idf_doc2</th>\n",
       "      <th>tf_idf_doc3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>future</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>energy</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>creation</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>economic</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>companies</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>workers</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  tf_idf_doc1  tf_idf_doc2  tf_idf_doc3\n",
       "1981     future     0.014967          NaN          NaN\n",
       "283      energy     0.011048     0.008275          NaN\n",
       "782    creation     0.005987          NaN          NaN\n",
       "805    economic     0.005987          NaN          NaN\n",
       "809   companies     0.005987          NaN          NaN\n",
       "811     workers     0.005987          NaN          NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare all three articles\n",
    "blob1 = tb(sample1)\n",
    "blob2 = blob1.noun_phrases\n",
    "term_freq = [tf(word,blob1) for word in blob1.words]\n",
    "tf_df1 = pd.DataFrame({'word': blob1.words, 'doc1_term_freq': term_freq})\n",
    "\n",
    "blob2 = tb(sample2)\n",
    "term_freq = [tf(word,blob2) for word in blob2.words]\n",
    "tf_df2 = pd.DataFrame({'word': blob2.words, 'doc2_term_freq': term_freq})\n",
    "\n",
    "blob3 = tb(sample3)\n",
    "term_freq = [tf(word,blob3) for word in blob3.words]\n",
    "tf_df3 = pd.DataFrame({'word': blob3.words, 'doc3_term_freq': term_freq})\n",
    "\n",
    "all_tf = pd.merge(pd.merge(tf_df1,tf_df2,on='word',how='outer'),tf_df3,on='word',how='outer').drop_duplicates()\n",
    "\n",
    "bloblist = [blob1,blob2,blob3]\n",
    "\n",
    "docs_containing1 = pd.DataFrame({'word': blob1.words, 'doc_freq': [n_containing(word,bloblist) for word in blob1.words]})\n",
    "docs_containing2 = pd.DataFrame({'word': blob2.words, 'doc_freq': [n_containing(word,bloblist) for word in blob2.words]})\n",
    "docs_containing3 = pd.DataFrame({'word': blob3.words, 'doc_freq': [n_containing(word,bloblist) for word in blob3.words]})\n",
    "\n",
    "doc_freq = pd.concat([docs_containing1,docs_containing2,docs_containing3]).drop_duplicates().reset_index(drop=True)\n",
    "df = pd.merge(doc_freq,all_tf,on='word',how='inner')\n",
    "df = df.sort_values(\"doc_freq\",ascending=False)\n",
    "\n",
    "df['intermediate_calc'] = (len(bloblist) / df['doc_freq']).astype(float)\n",
    "df['idf'] = df['intermediate_calc'].apply(math.log)\n",
    "df = df.sort_values(\"idf\",ascending=True)\n",
    "\n",
    "\n",
    "scores1 = pd.DataFrame({'word': blob1.words, 'tf_idf_doc1': [tfidf(word, blob1, bloblist) for word in blob1.words]})\n",
    "scores2 = pd.DataFrame({'word': blob2.words, 'tf_idf_doc2': [tfidf(word, blob2, bloblist) for word in blob2.words]})\n",
    "scores3 = pd.DataFrame({'word': blob3.words, 'tf_idf_doc3': [tfidf(word, blob3, bloblist) for word in blob3.words]})\n",
    "\n",
    "all_tfidf= pd.merge(pd.merge(scores1,scores2,on='word',how='outer'),scores3,on='word',how='outer').drop_duplicates()\n",
    "all_tfidf = all_tfidf[['word', 'tf_idf_doc1', 'tf_idf_doc2', 'tf_idf_doc3']]\n",
    "all_tfidf = all_tfidf.sort_values(by=['tf_idf_doc1', 'tf_idf_doc2','tf_idf_doc3'], ascending=[False,False,False])\n",
    "all_tfidf.head(n=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf_idf_doc1</th>\n",
       "      <th>tf_idf_doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>future</td>\n",
       "      <td>0.009443</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>back</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>new</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>white</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>house</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>job</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  tf_idf_doc1  tf_idf_doc2\n",
       "501  future     0.009443          NaN\n",
       "360    back     0.007555          NaN\n",
       "242     new     0.005666          NaN\n",
       "592   white     0.005666          NaN\n",
       "595   house     0.005666          NaN\n",
       "249     job     0.003777          NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Compare just the two articles we know to be similar\n",
    "two_tf = pd.merge(tf_df1,tf_df2,on='word',how='outer').drop_duplicates()\n",
    "\n",
    "bloblist = [blob1,blob2]\n",
    "\n",
    "docs_containing1 = pd.DataFrame({'word': blob1.words, 'doc_freq': [n_containing(word,bloblist) for word in blob1.words]})\n",
    "docs_containing2 = pd.DataFrame({'word': blob2.words, 'doc_freq': [n_containing(word,bloblist) for word in blob2.words]})\n",
    "\n",
    "doc_freq = pd.concat([docs_containing1,docs_containing2]).drop_duplicates().reset_index(drop=True)\n",
    "df = pd.merge(doc_freq,two_tf,on='word',how='inner')\n",
    "df = df.sort_values(\"doc_freq\",ascending=False)\n",
    "\n",
    "df['intermediate_calc'] = (len(bloblist) / df['doc_freq']).astype(float)\n",
    "df['idf'] = df['intermediate_calc'].apply(math.log)\n",
    "df = df.sort_values(\"idf\",ascending=False)\n",
    "\n",
    "scores1 = pd.DataFrame({'word': blob1.words, 'tf_idf_doc1': [tfidf(word, blob1, bloblist) for word in blob1.words]})\n",
    "scores2 = pd.DataFrame({'word': blob2.words, 'tf_idf_doc2': [tfidf(word, blob2, bloblist) for word in blob2.words]})\n",
    "\n",
    "two_tfidf= pd.merge(scores1,scores2,on='word',how='outer').drop_duplicates()\n",
    "two_tfidf = two_tfidf[['word', 'tf_idf_doc1', 'tf_idf_doc2']]\n",
    "two_tfidf = two_tfidf.sort_values(by=['tf_idf_doc1', 'tf_idf_doc2'], ascending=[False,False])\n",
    "two_tfidf.head(n=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compare all three using all pre-defined functions\n",
    "bloblist2 = [blob1,blob2,blob3]\n",
    "for i, blob in enumerate(bloblist2):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#compare similar docs using all pre-defined functions\n",
    "bloblist3 = [blob1,blob2]\n",
    "for i, blob in enumerate(bloblist3):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 24\n",
      "\tWord: energy, TF-IDF: 0.04677\n",
      "\tWord: future, TF-IDF: 0.02339\n",
      "\tWord: era, TF-IDF: 0.02328\n",
      "\tWord: coal, TF-IDF: 0.02328\n",
      "\tWord: power, TF-IDF: 0.01896\n",
      "\tWord: emissions, TF-IDF: 0.01871\n",
      "\tWord: carbon, TF-IDF: 0.01746\n",
      "\tWord: action, TF-IDF: 0.01746\n",
      "\tWord: executive, TF-IDF: 0.01534\n",
      "\tWord: environmental, TF-IDF: 0.01534\n",
      "Top words in document 25\n",
      "\tWord: q, TF-IDF: 0.06141\n",
      "\tWord: mr, TF-IDF: 0.04138\n",
      "\tWord: spicer, TF-IDF: 0.0264\n",
      "\tWord: vote, TF-IDF: 0.01818\n",
      "\tWord: healthcare, TF-IDF: 0.01474\n",
      "\tWord: reform, TF-IDF: 0.01474\n",
      "\tWord: tax, TF-IDF: 0.01347\n",
      "\tWord: people, TF-IDF: 0.01317\n",
      "\tWord: american, TF-IDF: 0.01254\n",
      "\tWord: obamacare, TF-IDF: 0.01228\n",
      "Top words in document 26\n",
      "\tWord: fbi, TF-IDF: 0.0429\n",
      "\tWord: russia, TF-IDF: 0.03786\n",
      "\tWord: steele, TF-IDF: 0.03544\n",
      "\tWord: intelligence, TF-IDF: 0.0284\n",
      "\tWord: russian, TF-IDF: 0.02577\n",
      "\tWord: cia, TF-IDF: 0.02255\n",
      "\tWord: co, TF-IDF: 0.01933\n",
      "\tWord: investigation, TF-IDF: 0.01767\n",
      "\tWord: voter, TF-IDF: 0.01611\n",
      "\tWord: kalugin, TF-IDF: 0.01611\n",
      "Top words in document 27\n",
      "\tWord: subsection, TF-IDF: 0.04175\n",
      "\tWord: effective, TF-IDF: 0.04175\n",
      "\tWord: section, TF-IDF: 0.03816\n",
      "\tWord: homeland, TF-IDF: 0.03552\n",
      "\tWord: nationals, TF-IDF: 0.03479\n",
      "\tWord: submit, TF-IDF: 0.03479\n",
      "\tWord: date, TF-IDF: 0.03271\n",
      "\tWord: attorney, TF-IDF: 0.02783\n",
      "\tWord: consultation, TF-IDF: 0.02783\n",
      "\tWord: review, TF-IDF: 0.02726\n",
      "Top words in document 28\n",
      "\tWord: energy, TF-IDF: 0.03664\n",
      "\tWord: power, TF-IDF: 0.02971\n",
      "\tWord: paris, TF-IDF: 0.0291\n",
      "\tWord: climate, TF-IDF: 0.02475\n",
      "\tWord: clean, TF-IDF: 0.02475\n",
      "\tWord: coal, TF-IDF: 0.02279\n",
      "\tWord: environmental, TF-IDF: 0.02003\n",
      "\tWord: undo, TF-IDF: 0.0194\n",
      "\tWord: activist, TF-IDF: 0.0194\n",
      "\tWord: green, TF-IDF: 0.0194\n",
      "Top words in document 29\n",
      "\tWord: fcc, TF-IDF: 0.04799\n",
      "\tWord: internet, TF-IDF: 0.04512\n",
      "\tWord: information, TF-IDF: 0.0392\n",
      "\tWord: isps, TF-IDF: 0.0384\n",
      "\tWord: data, TF-IDF: 0.0384\n",
      "\tWord: privacy, TF-IDF: 0.0288\n",
      "\tWord: history, TF-IDF: 0.0288\n",
      "\tWord: users, TF-IDF: 0.0288\n",
      "\tWord: advocates, TF-IDF: 0.0288\n",
      "\tWord: rules, TF-IDF: 0.01983\n",
      "Top words in document 30\n",
      "\tWord: border, TF-IDF: 0.03973\n",
      "\tWord: miles, TF-IDF: 0.03505\n",
      "\tWord: km, TF-IDF: 0.03505\n",
      "\tWord: construction, TF-IDF: 0.03295\n",
      "\tWord: report, TF-IDF: 0.03221\n",
      "\tWord: texas, TF-IDF: 0.02746\n",
      "\tWord: mexico, TF-IDF: 0.02649\n",
      "\tWord: reuters, TF-IDF: 0.02103\n",
      "\tWord: dhs, TF-IDF: 0.02103\n",
      "\tWord: estimates, TF-IDF: 0.01648\n",
      "Top words in document 31\n",
      "\tWord: trade, TF-IDF: 0.14032\n",
      "\tWord: deficit, TF-IDF: 0.05374\n",
      "\tWord: china, TF-IDF: 0.05374\n",
      "\tWord: navarro, TF-IDF: 0.04478\n",
      "\tWord: japan, TF-IDF: 0.02806\n",
      "\tWord: nations, TF-IDF: 0.02806\n",
      "\tWord: bilateral, TF-IDF: 0.02687\n",
      "\tWord: mr, TF-IDF: 0.02286\n",
      "\tWord: deficits, TF-IDF: 0.02105\n",
      "\tWord: pacific, TF-IDF: 0.01791\n",
      "Top words in document 32\n",
      "\tWord: small, TF-IDF: 0.06297\n",
      "\tWord: business, TF-IDF: 0.05062\n",
      "\tWord: korzenik, TF-IDF: 0.04593\n",
      "\tWord: toledo, TF-IDF: 0.03445\n",
      "\tWord: election, TF-IDF: 0.02699\n",
      "\tWord: care, TF-IDF: 0.02699\n",
      "\tWord: confidence, TF-IDF: 0.02699\n",
      "\tWord: mr, TF-IDF: 0.02345\n",
      "\tWord: businesses, TF-IDF: 0.02297\n",
      "\tWord: owner, TF-IDF: 0.02297\n",
      "Top words in document 33\n",
      "\tWord: budget, TF-IDF: 0.06681\n",
      "\tWord: cuts, TF-IDF: 0.03031\n",
      "\tWord: proposal, TF-IDF: 0.02375\n",
      "\tWord: mulvaney, TF-IDF: 0.02273\n",
      "\tWord: bn, TF-IDF: 0.02273\n",
      "\tWord: aid, TF-IDF: 0.02273\n",
      "\tWord: programs, TF-IDF: 0.02273\n",
      "\tWord: epa, TF-IDF: 0.01781\n",
      "\tWord: power, TF-IDF: 0.01547\n",
      "\tWord: veterans, TF-IDF: 0.01516\n",
      "Top words in document 34\n",
      "\tWord: robart, TF-IDF: 0.08088\n",
      "\tWord: judge, TF-IDF: 0.06336\n",
      "\tWord: mr, TF-IDF: 0.04719\n",
      "\tWord: ban, TF-IDF: 0.03621\n",
      "\tWord: check, TF-IDF: 0.03466\n",
      "\tWord: independent, TF-IDF: 0.02715\n",
      "\tWord: bush, TF-IDF: 0.02311\n",
      "\tWord: appointee, TF-IDF: 0.02311\n",
      "\tWord: tweets, TF-IDF: 0.0181\n",
      "\tWord: gorsuch, TF-IDF: 0.0181\n",
      "Top words in document 36\n",
      "\tWord: flemings, TF-IDF: 0.06077\n",
      "\tWord: irs, TF-IDF: 0.04862\n",
      "\tWord: date, TF-IDF: 0.03809\n",
      "\tWord: job, TF-IDF: 0.03723\n",
      "\tWord: january, TF-IDF: 0.03646\n",
      "\tWord: austin, TF-IDF: 0.03646\n",
      "\tWord: people, TF-IDF: 0.02482\n",
      "\tWord: employees, TF-IDF: 0.02431\n",
      "\tWord: management, TF-IDF: 0.02431\n",
      "\tWord: sessions, TF-IDF: 0.02431\n",
      "Top words in document 39\n",
      "\tWord: gorsuch, TF-IDF: 0.06835\n",
      "\tWord: republicans, TF-IDF: 0.04349\n",
      "\tWord: r, TF-IDF: 0.03966\n",
      "\tWord: democrats, TF-IDF: 0.03107\n",
      "\tWord: court, TF-IDF: 0.02621\n",
      "\tWord: confirmation, TF-IDF: 0.02485\n",
      "\tWord: supreme, TF-IDF: 0.02485\n",
      "\tWord: senators, TF-IDF: 0.02379\n",
      "\tWord: nominees, TF-IDF: 0.02379\n",
      "\tWord: filibuster, TF-IDF: 0.02379\n"
     ]
    }
   ],
   "source": [
    "#compare all DSIs sing all pre-defined functions\n",
    "DSI_list = all_documents[\"DSInum\"]\n",
    "for i, blob in enumerate(blob_list):\n",
    "    print(\"Top words in document {}\".format(DSI_list[i]))\n",
    "    scores = {word: tfidf(word, blob, blob_list) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
